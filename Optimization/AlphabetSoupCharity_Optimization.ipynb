{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "QpXOfvDSYo8D"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "jS4D__TuZ-WC"
      },
      "outputs": [],
      "source": [
        "# Load dataset from the cloud URL\n",
        "url = \"https://static.bc-edx.com/data/dl-1-2/m21/lms/starter/charity_data.csv\"\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "# Drop non-beneficial columns (EIN and NAME)\n",
        "df = df.drop(columns=[\"EIN\", \"NAME\"])\n",
        "\n",
        "# Group less common APPLICATION_TYPEs into \"Other\"\n",
        "app_cutoff = 500  # Adjust as needed\n",
        "app_to_replace = df[\"APPLICATION_TYPE\"].value_counts()[df[\"APPLICATION_TYPE\"].value_counts() < app_cutoff].index\n",
        "df[\"APPLICATION_TYPE\"] = df[\"APPLICATION_TYPE\"].replace(app_to_replace, \"Other\")\n",
        "\n",
        "# Group less common CLASSIFICATIONs into \"Other\"\n",
        "class_cutoff = 1000  # Adjust as needed\n",
        "class_to_replace = df[\"CLASSIFICATION\"].value_counts()[df[\"CLASSIFICATION\"].value_counts() < class_cutoff].index\n",
        "df[\"CLASSIFICATION\"] = df[\"CLASSIFICATION\"].replace(class_to_replace, \"Other\")\n",
        "\n",
        "# One-hot encode categorical variables\n",
        "df = pd.get_dummies(df, dtype=int)\n",
        "\n",
        "# Split into features (X) and target (y)\n",
        "X = df.drop(columns=[\"IS_SUCCESSFUL\"]).values\n",
        "y = df[\"IS_SUCCESSFUL\"].values\n",
        "\n",
        "# Split into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize numerical features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lI9NXWizsYUX",
        "outputId": "a5ec6fb4-fc9e-4dac-a096-2565d7af3d82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "IS_SUCCESSFUL                   1.000000\n",
            "AFFILIATION_Independent         0.368322\n",
            "ORGANIZATION_Trust              0.162164\n",
            "CLASSIFICATION_Other            0.111202\n",
            "APPLICATION_TYPE_T5             0.088575\n",
            "APPLICATION_TYPE_T10            0.086805\n",
            "APPLICATION_TYPE_T6             0.079817\n",
            "INCOME_AMT_1-9999               0.067058\n",
            "CLASSIFICATION_C1000            0.062589\n",
            "ORGANIZATION_Co-operative       0.053520\n",
            "APPLICATION_TYPE_Other          0.045165\n",
            "INCOME_AMT_10000-24999          0.036937\n",
            "INCOME_AMT_100000-499999        0.030542\n",
            "INCOME_AMT_25000-99999          0.026239\n",
            "USE_CASE_Preservation           0.024145\n",
            "ORGANIZATION_Corporation        0.016690\n",
            "AFFILIATION_Other               0.010121\n",
            "APPLICATION_TYPE_T7             0.009752\n",
            "USE_CASE_Other                  0.008765\n",
            "SPECIAL_CONSIDERATIONS_Y        0.005469\n",
            "AFFILIATION_National            0.004581\n",
            "AFFILIATION_Regional            0.003238\n",
            "AFFILIATION_Family/Parent       0.002608\n",
            "CLASSIFICATION_C2000           -0.000434\n",
            "APPLICATION_TYPE_T3            -0.000953\n",
            "STATUS                         -0.001636\n",
            "SPECIAL_CONSIDERATIONS_N       -0.005469\n",
            "INCOME_AMT_5M-10M              -0.009171\n",
            "ASK_AMT                        -0.010861\n",
            "USE_CASE_ProductDev            -0.011841\n",
            "USE_CASE_Heathcare             -0.013222\n",
            "INCOME_AMT_10M-50M             -0.021575\n",
            "INCOME_AMT_1M-5M               -0.022535\n",
            "CLASSIFICATION_C3000           -0.023182\n",
            "INCOME_AMT_50M+                -0.024838\n",
            "APPLICATION_TYPE_T8            -0.032796\n",
            "USE_CASE_CommunityServ         -0.039122\n",
            "INCOME_AMT_0                   -0.052509\n",
            "CLASSIFICATION_C1200           -0.056621\n",
            "APPLICATION_TYPE_T4            -0.098692\n",
            "APPLICATION_TYPE_T19           -0.123303\n",
            "CLASSIFICATION_C2100           -0.147895\n",
            "ORGANIZATION_Association       -0.179561\n",
            "AFFILIATION_CompanySponsored   -0.369379\n",
            "Name: IS_SUCCESSFUL, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# Check correlation of numerical features with the target variable\n",
        "correlation = df.corr()[\"IS_SUCCESSFUL\"].sort_values(ascending=False)\n",
        "print(correlation)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "PypgdAHUtYQs"
      },
      "outputs": [],
      "source": [
        "# Drop low-correlation and noisy features\n",
        "df = df.drop(columns=[\n",
        "    \"ASK_AMT\", \"SPECIAL_CONSIDERATIONS_N\", \"SPECIAL_CONSIDERATIONS_Y\",\n",
        "    \"STATUS\", \"USE_CASE_Other\", \"AFFILIATION_Family/Parent\",\n",
        "    \"AFFILIATION_Regional\", \"APPLICATION_TYPE_T3\", \"APPLICATION_TYPE_T7\"\n",
        "])\n",
        "\n",
        "# Re-define X (features) and y (target)\n",
        "X = df.drop(columns=[\"IS_SUCCESSFUL\"]).values  # Features\n",
        "y = df[\"IS_SUCCESSFUL\"].values  # Target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "id": "s0VPUgundVJP",
        "outputId": "5ff161e6-03f3-4ac9-bb94-b29fa172d0bb"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_6\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_6\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">5,632</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_20 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │           \u001b[38;5;34m5,632\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_21 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m8,256\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_22 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │           \u001b[38;5;34m2,080\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_23 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m33\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">16,001</span> (62.50 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m16,001\u001b[0m (62.50 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">16,001</span> (62.50 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m16,001\u001b[0m (62.50 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Initialize the Sequential model\n",
        "nn = Sequential()\n",
        "\n",
        "# Explicitly define input shape\n",
        "nn.add(Input(shape=(X_train_scaled.shape[1],)))\n",
        "\n",
        "# First hidden layer (more neurons)\n",
        "nn.add(Dense(units=128, activation=\"relu\"))  #First attempted with 100 units, then finally with 128 units\n",
        "\n",
        "# Second hidden layer (more neurons)\n",
        "nn.add(Dense(units=64, activation=\"relu\"))   #First attempted with 50 units, then finally with 64 units\n",
        "\n",
        "# Third hidden layer (NEW LAYER)\n",
        "nn.add(Dense(units=32, activation=\"relu\"))  # Added third hidden layer of 25 units after the first attempt. Increased to 32 units in the third attempt\n",
        "\n",
        "# Output layer (Binary classification)\n",
        "nn.add(Dense(units=1, activation=\"sigmoid\"))\n",
        "\n",
        "# Check the model structure\n",
        "nn.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4IdHFcY4eDS-",
        "outputId": "2fcfef2f-e826-43be-aa8e-064ce6dec335"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7152 - loss: 0.5816 - val_accuracy: 0.7262 - val_loss: 0.5660\n",
            "Epoch 2/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7296 - loss: 0.5563 - val_accuracy: 0.7255 - val_loss: 0.5652\n",
            "Epoch 3/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7290 - loss: 0.5521 - val_accuracy: 0.7278 - val_loss: 0.5612\n",
            "Epoch 4/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7343 - loss: 0.5463 - val_accuracy: 0.7270 - val_loss: 0.5604\n",
            "Epoch 5/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7330 - loss: 0.5482 - val_accuracy: 0.7223 - val_loss: 0.5568\n",
            "Epoch 6/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7343 - loss: 0.5450 - val_accuracy: 0.7273 - val_loss: 0.5581\n",
            "Epoch 7/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7308 - loss: 0.5460 - val_accuracy: 0.7251 - val_loss: 0.5592\n",
            "Epoch 8/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7362 - loss: 0.5416 - val_accuracy: 0.7283 - val_loss: 0.5573\n",
            "Epoch 9/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7349 - loss: 0.5441 - val_accuracy: 0.7265 - val_loss: 0.5569\n",
            "Epoch 10/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7387 - loss: 0.5378 - val_accuracy: 0.7274 - val_loss: 0.5565\n",
            "Epoch 11/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7385 - loss: 0.5388 - val_accuracy: 0.7264 - val_loss: 0.5589\n",
            "Epoch 12/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7385 - loss: 0.5410 - val_accuracy: 0.7222 - val_loss: 0.5630\n",
            "Epoch 13/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7346 - loss: 0.5469 - val_accuracy: 0.7232 - val_loss: 0.5590\n",
            "Epoch 14/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7388 - loss: 0.5379 - val_accuracy: 0.7248 - val_loss: 0.5602\n",
            "Epoch 15/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7350 - loss: 0.5436 - val_accuracy: 0.7241 - val_loss: 0.5605\n",
            "Epoch 16/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7363 - loss: 0.5415 - val_accuracy: 0.7254 - val_loss: 0.5576\n",
            "Epoch 17/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7348 - loss: 0.5426 - val_accuracy: 0.7248 - val_loss: 0.5592\n",
            "Epoch 18/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7351 - loss: 0.5435 - val_accuracy: 0.7243 - val_loss: 0.5611\n",
            "Epoch 19/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7385 - loss: 0.5423 - val_accuracy: 0.7297 - val_loss: 0.5591\n",
            "Epoch 20/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7373 - loss: 0.5401 - val_accuracy: 0.7258 - val_loss: 0.5596\n",
            "Epoch 21/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7350 - loss: 0.5425 - val_accuracy: 0.7249 - val_loss: 0.5600\n",
            "Epoch 22/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7360 - loss: 0.5404 - val_accuracy: 0.7261 - val_loss: 0.5572\n",
            "Epoch 23/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7373 - loss: 0.5419 - val_accuracy: 0.7262 - val_loss: 0.5592\n",
            "Epoch 24/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7335 - loss: 0.5416 - val_accuracy: 0.7252 - val_loss: 0.5598\n",
            "Epoch 25/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7380 - loss: 0.5353 - val_accuracy: 0.7280 - val_loss: 0.5602\n",
            "Epoch 26/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7427 - loss: 0.5335 - val_accuracy: 0.7255 - val_loss: 0.5589\n",
            "Epoch 27/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7333 - loss: 0.5392 - val_accuracy: 0.7277 - val_loss: 0.5624\n",
            "Epoch 28/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7448 - loss: 0.5301 - val_accuracy: 0.7274 - val_loss: 0.5612\n",
            "Epoch 29/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7354 - loss: 0.5423 - val_accuracy: 0.7270 - val_loss: 0.5617\n",
            "Epoch 30/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7422 - loss: 0.5314 - val_accuracy: 0.7278 - val_loss: 0.5619\n",
            "Epoch 31/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7387 - loss: 0.5371 - val_accuracy: 0.7276 - val_loss: 0.5608\n",
            "Epoch 32/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7400 - loss: 0.5394 - val_accuracy: 0.7249 - val_loss: 0.5646\n",
            "Epoch 33/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7401 - loss: 0.5385 - val_accuracy: 0.7254 - val_loss: 0.5619\n",
            "Epoch 34/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7389 - loss: 0.5373 - val_accuracy: 0.7222 - val_loss: 0.5628\n",
            "Epoch 35/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7353 - loss: 0.5390 - val_accuracy: 0.7267 - val_loss: 0.5626\n",
            "Epoch 36/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7396 - loss: 0.5344 - val_accuracy: 0.7238 - val_loss: 0.5640\n",
            "Epoch 37/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7354 - loss: 0.5403 - val_accuracy: 0.7235 - val_loss: 0.5666\n",
            "Epoch 38/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7388 - loss: 0.5372 - val_accuracy: 0.7254 - val_loss: 0.5656\n",
            "Epoch 39/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7409 - loss: 0.5356 - val_accuracy: 0.7287 - val_loss: 0.5632\n",
            "Epoch 40/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7389 - loss: 0.5363 - val_accuracy: 0.7258 - val_loss: 0.5644\n",
            "Epoch 41/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7360 - loss: 0.5396 - val_accuracy: 0.7254 - val_loss: 0.5640\n",
            "Epoch 42/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7396 - loss: 0.5351 - val_accuracy: 0.7281 - val_loss: 0.5661\n",
            "Epoch 43/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7435 - loss: 0.5323 - val_accuracy: 0.7267 - val_loss: 0.5641\n",
            "Epoch 44/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7366 - loss: 0.5370 - val_accuracy: 0.7274 - val_loss: 0.5657\n",
            "Epoch 45/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7405 - loss: 0.5332 - val_accuracy: 0.7255 - val_loss: 0.5681\n",
            "Epoch 46/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7418 - loss: 0.5350 - val_accuracy: 0.7262 - val_loss: 0.5670\n",
            "Epoch 47/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7415 - loss: 0.5339 - val_accuracy: 0.7265 - val_loss: 0.5675\n",
            "Epoch 48/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7383 - loss: 0.5336 - val_accuracy: 0.7259 - val_loss: 0.5717\n",
            "Epoch 49/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7435 - loss: 0.5335 - val_accuracy: 0.7268 - val_loss: 0.5671\n",
            "Epoch 50/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7345 - loss: 0.5391 - val_accuracy: 0.7273 - val_loss: 0.5673\n",
            "Epoch 51/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7405 - loss: 0.5299 - val_accuracy: 0.7281 - val_loss: 0.5640\n",
            "Epoch 52/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7432 - loss: 0.5286 - val_accuracy: 0.7252 - val_loss: 0.5710\n",
            "Epoch 53/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7432 - loss: 0.5298 - val_accuracy: 0.7273 - val_loss: 0.5679\n",
            "Epoch 54/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7428 - loss: 0.5322 - val_accuracy: 0.7254 - val_loss: 0.5653\n",
            "Epoch 55/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7382 - loss: 0.5367 - val_accuracy: 0.7265 - val_loss: 0.5707\n",
            "Epoch 56/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7408 - loss: 0.5320 - val_accuracy: 0.7257 - val_loss: 0.5708\n",
            "Epoch 57/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7426 - loss: 0.5324 - val_accuracy: 0.7276 - val_loss: 0.5698\n",
            "Epoch 58/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7410 - loss: 0.5329 - val_accuracy: 0.7268 - val_loss: 0.5715\n",
            "Epoch 59/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7439 - loss: 0.5322 - val_accuracy: 0.7271 - val_loss: 0.5717\n",
            "Epoch 60/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7344 - loss: 0.5391 - val_accuracy: 0.7274 - val_loss: 0.5737\n",
            "Epoch 61/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7377 - loss: 0.5355 - val_accuracy: 0.7264 - val_loss: 0.5728\n",
            "Epoch 62/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7398 - loss: 0.5335 - val_accuracy: 0.7262 - val_loss: 0.5716\n",
            "Epoch 63/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7355 - loss: 0.5397 - val_accuracy: 0.7257 - val_loss: 0.5784\n",
            "Epoch 64/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7449 - loss: 0.5291 - val_accuracy: 0.7277 - val_loss: 0.5711\n",
            "Epoch 65/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7427 - loss: 0.5315 - val_accuracy: 0.7276 - val_loss: 0.5703\n",
            "Epoch 66/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7392 - loss: 0.5336 - val_accuracy: 0.7257 - val_loss: 0.5714\n",
            "Epoch 67/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7428 - loss: 0.5302 - val_accuracy: 0.7277 - val_loss: 0.5731\n",
            "Epoch 68/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7385 - loss: 0.5363 - val_accuracy: 0.7293 - val_loss: 0.5804\n",
            "Epoch 69/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7408 - loss: 0.5321 - val_accuracy: 0.7268 - val_loss: 0.5777\n",
            "Epoch 70/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7421 - loss: 0.5324 - val_accuracy: 0.7273 - val_loss: 0.5773\n",
            "Epoch 71/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7381 - loss: 0.5329 - val_accuracy: 0.7280 - val_loss: 0.5746\n",
            "Epoch 72/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7407 - loss: 0.5311 - val_accuracy: 0.7270 - val_loss: 0.5793\n",
            "Epoch 73/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7397 - loss: 0.5332 - val_accuracy: 0.7283 - val_loss: 0.5759\n",
            "Epoch 74/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7428 - loss: 0.5341 - val_accuracy: 0.7280 - val_loss: 0.5729\n",
            "Epoch 75/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7351 - loss: 0.5368 - val_accuracy: 0.7273 - val_loss: 0.5786\n",
            "Epoch 76/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7411 - loss: 0.5350 - val_accuracy: 0.7283 - val_loss: 0.5787\n",
            "Epoch 77/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7402 - loss: 0.5371 - val_accuracy: 0.7265 - val_loss: 0.5769\n",
            "Epoch 78/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7411 - loss: 0.5325 - val_accuracy: 0.7255 - val_loss: 0.5806\n",
            "Epoch 79/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.7489 - loss: 0.5261 - val_accuracy: 0.7270 - val_loss: 0.5735\n",
            "Epoch 80/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7443 - loss: 0.5300 - val_accuracy: 0.7254 - val_loss: 0.5795\n",
            "Epoch 81/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7407 - loss: 0.5353 - val_accuracy: 0.7268 - val_loss: 0.5793\n",
            "Epoch 82/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7387 - loss: 0.5358 - val_accuracy: 0.7267 - val_loss: 0.5794\n",
            "Epoch 83/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7423 - loss: 0.5308 - val_accuracy: 0.7258 - val_loss: 0.5820\n",
            "Epoch 84/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7470 - loss: 0.5248 - val_accuracy: 0.7273 - val_loss: 0.5772\n",
            "Epoch 85/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7399 - loss: 0.5334 - val_accuracy: 0.7267 - val_loss: 0.5832\n",
            "Epoch 86/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7440 - loss: 0.5279 - val_accuracy: 0.7270 - val_loss: 0.5872\n",
            "Epoch 87/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7425 - loss: 0.5299 - val_accuracy: 0.7276 - val_loss: 0.5797\n",
            "Epoch 88/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7419 - loss: 0.5304 - val_accuracy: 0.7261 - val_loss: 0.5846\n",
            "Epoch 89/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7364 - loss: 0.5346 - val_accuracy: 0.7273 - val_loss: 0.5833\n",
            "Epoch 90/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7394 - loss: 0.5327 - val_accuracy: 0.7264 - val_loss: 0.5838\n",
            "Epoch 91/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7409 - loss: 0.5321 - val_accuracy: 0.7208 - val_loss: 0.5813\n",
            "Epoch 92/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7397 - loss: 0.5316 - val_accuracy: 0.7278 - val_loss: 0.5839\n",
            "Epoch 93/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7400 - loss: 0.5328 - val_accuracy: 0.7259 - val_loss: 0.5821\n",
            "Epoch 94/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7425 - loss: 0.5285 - val_accuracy: 0.7246 - val_loss: 0.5871\n",
            "Epoch 95/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7451 - loss: 0.5254 - val_accuracy: 0.7261 - val_loss: 0.5868\n",
            "Epoch 96/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7414 - loss: 0.5304 - val_accuracy: 0.7281 - val_loss: 0.5834\n",
            "Epoch 97/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7412 - loss: 0.5305 - val_accuracy: 0.7281 - val_loss: 0.5818\n",
            "Epoch 98/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7422 - loss: 0.5297 - val_accuracy: 0.7278 - val_loss: 0.5894\n",
            "Epoch 99/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7415 - loss: 0.5321 - val_accuracy: 0.7278 - val_loss: 0.5830\n",
            "Epoch 100/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7392 - loss: 0.5327 - val_accuracy: 0.7278 - val_loss: 0.5829\n",
            "Epoch 101/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7414 - loss: 0.5318 - val_accuracy: 0.7236 - val_loss: 0.5825\n",
            "Epoch 102/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7413 - loss: 0.5319 - val_accuracy: 0.7278 - val_loss: 0.5818\n",
            "Epoch 103/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7391 - loss: 0.5335 - val_accuracy: 0.7280 - val_loss: 0.5893\n",
            "Epoch 104/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7447 - loss: 0.5276 - val_accuracy: 0.7283 - val_loss: 0.5911\n",
            "Epoch 105/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7431 - loss: 0.5297 - val_accuracy: 0.7230 - val_loss: 0.5926\n",
            "Epoch 106/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7352 - loss: 0.5338 - val_accuracy: 0.7265 - val_loss: 0.5862\n",
            "Epoch 107/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7445 - loss: 0.5282 - val_accuracy: 0.7258 - val_loss: 0.5877\n",
            "Epoch 108/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7418 - loss: 0.5309 - val_accuracy: 0.7281 - val_loss: 0.5922\n",
            "Epoch 109/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7429 - loss: 0.5275 - val_accuracy: 0.7274 - val_loss: 0.5825\n",
            "Epoch 110/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7391 - loss: 0.5319 - val_accuracy: 0.7287 - val_loss: 0.5897\n",
            "Epoch 111/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7430 - loss: 0.5289 - val_accuracy: 0.7277 - val_loss: 0.5907\n",
            "Epoch 112/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7389 - loss: 0.5308 - val_accuracy: 0.7280 - val_loss: 0.5882\n",
            "Epoch 113/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7432 - loss: 0.5290 - val_accuracy: 0.7278 - val_loss: 0.5955\n",
            "Epoch 114/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7394 - loss: 0.5313 - val_accuracy: 0.7273 - val_loss: 0.5920\n",
            "Epoch 115/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7454 - loss: 0.5273 - val_accuracy: 0.7273 - val_loss: 0.5970\n",
            "Epoch 116/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7365 - loss: 0.5364 - val_accuracy: 0.7286 - val_loss: 0.5947\n",
            "Epoch 117/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7488 - loss: 0.5205 - val_accuracy: 0.7277 - val_loss: 0.5884\n",
            "Epoch 118/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7440 - loss: 0.5258 - val_accuracy: 0.7274 - val_loss: 0.5922\n",
            "Epoch 119/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7409 - loss: 0.5294 - val_accuracy: 0.7268 - val_loss: 0.6026\n",
            "Epoch 120/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7384 - loss: 0.5339 - val_accuracy: 0.7278 - val_loss: 0.5973\n",
            "Epoch 121/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7428 - loss: 0.5284 - val_accuracy: 0.7261 - val_loss: 0.5966\n",
            "Epoch 122/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7468 - loss: 0.5265 - val_accuracy: 0.7290 - val_loss: 0.5896\n",
            "Epoch 123/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7408 - loss: 0.5305 - val_accuracy: 0.7278 - val_loss: 0.5949\n",
            "Epoch 124/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7417 - loss: 0.5287 - val_accuracy: 0.7284 - val_loss: 0.5839\n",
            "Epoch 125/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7434 - loss: 0.5302 - val_accuracy: 0.7280 - val_loss: 0.6017\n",
            "Epoch 126/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7398 - loss: 0.5330 - val_accuracy: 0.7276 - val_loss: 0.5922\n",
            "Epoch 127/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7415 - loss: 0.5280 - val_accuracy: 0.7268 - val_loss: 0.5909\n",
            "Epoch 128/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7449 - loss: 0.5290 - val_accuracy: 0.7252 - val_loss: 0.6003\n",
            "Epoch 129/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7389 - loss: 0.5346 - val_accuracy: 0.7264 - val_loss: 0.5976\n",
            "Epoch 130/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7378 - loss: 0.5367 - val_accuracy: 0.7273 - val_loss: 0.5961\n",
            "Epoch 131/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7400 - loss: 0.5332 - val_accuracy: 0.7284 - val_loss: 0.5971\n",
            "Epoch 132/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7354 - loss: 0.5360 - val_accuracy: 0.7280 - val_loss: 0.6014\n",
            "Epoch 133/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7422 - loss: 0.5309 - val_accuracy: 0.7254 - val_loss: 0.6040\n",
            "Epoch 134/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7422 - loss: 0.5294 - val_accuracy: 0.7259 - val_loss: 0.5905\n",
            "Epoch 135/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7421 - loss: 0.5273 - val_accuracy: 0.7292 - val_loss: 0.5910\n",
            "Epoch 136/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7460 - loss: 0.5258 - val_accuracy: 0.7262 - val_loss: 0.5966\n",
            "Epoch 137/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7462 - loss: 0.5254 - val_accuracy: 0.7280 - val_loss: 0.5948\n",
            "Epoch 138/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7434 - loss: 0.5301 - val_accuracy: 0.7290 - val_loss: 0.5911\n",
            "Epoch 139/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7403 - loss: 0.5346 - val_accuracy: 0.7278 - val_loss: 0.5995\n",
            "Epoch 140/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7408 - loss: 0.5298 - val_accuracy: 0.7283 - val_loss: 0.5897\n",
            "Epoch 141/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7442 - loss: 0.5265 - val_accuracy: 0.7277 - val_loss: 0.5957\n",
            "Epoch 142/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7377 - loss: 0.5369 - val_accuracy: 0.7278 - val_loss: 0.5951\n",
            "Epoch 143/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7431 - loss: 0.5292 - val_accuracy: 0.7283 - val_loss: 0.6004\n",
            "Epoch 144/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7434 - loss: 0.5305 - val_accuracy: 0.7286 - val_loss: 0.5922\n",
            "Epoch 145/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7407 - loss: 0.5313 - val_accuracy: 0.7287 - val_loss: 0.5961\n",
            "Epoch 146/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7469 - loss: 0.5261 - val_accuracy: 0.7292 - val_loss: 0.5954\n",
            "Epoch 147/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7421 - loss: 0.5309 - val_accuracy: 0.7283 - val_loss: 0.6112\n",
            "Epoch 148/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7395 - loss: 0.5338 - val_accuracy: 0.7271 - val_loss: 0.5988\n",
            "Epoch 149/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7447 - loss: 0.5236 - val_accuracy: 0.7273 - val_loss: 0.5941\n",
            "Epoch 150/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7414 - loss: 0.5307 - val_accuracy: 0.7293 - val_loss: 0.5942\n",
            "Epoch 151/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7486 - loss: 0.5246 - val_accuracy: 0.7297 - val_loss: 0.5997\n",
            "Epoch 152/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7369 - loss: 0.5375 - val_accuracy: 0.7290 - val_loss: 0.5999\n",
            "Epoch 153/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7406 - loss: 0.5318 - val_accuracy: 0.7293 - val_loss: 0.6031\n",
            "Epoch 154/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7424 - loss: 0.5291 - val_accuracy: 0.7271 - val_loss: 0.6052\n",
            "Epoch 155/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7453 - loss: 0.5294 - val_accuracy: 0.7289 - val_loss: 0.6152\n",
            "Epoch 156/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7424 - loss: 0.5286 - val_accuracy: 0.7293 - val_loss: 0.6097\n",
            "Epoch 157/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7423 - loss: 0.5276 - val_accuracy: 0.7284 - val_loss: 0.6055\n",
            "Epoch 158/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7413 - loss: 0.5318 - val_accuracy: 0.7278 - val_loss: 0.6157\n",
            "Epoch 159/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7465 - loss: 0.5234 - val_accuracy: 0.7276 - val_loss: 0.6100\n",
            "Epoch 160/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7421 - loss: 0.5272 - val_accuracy: 0.7276 - val_loss: 0.6214\n",
            "Epoch 161/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7413 - loss: 0.5288 - val_accuracy: 0.7296 - val_loss: 0.6036\n",
            "Epoch 162/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7407 - loss: 0.5297 - val_accuracy: 0.7293 - val_loss: 0.6084\n",
            "Epoch 163/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7436 - loss: 0.5294 - val_accuracy: 0.7297 - val_loss: 0.6179\n",
            "Epoch 164/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7408 - loss: 0.5330 - val_accuracy: 0.7276 - val_loss: 0.6263\n",
            "Epoch 165/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7392 - loss: 0.5344 - val_accuracy: 0.7292 - val_loss: 0.6260\n",
            "Epoch 166/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7374 - loss: 0.5358 - val_accuracy: 0.7262 - val_loss: 0.6189\n",
            "Epoch 167/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7437 - loss: 0.5288 - val_accuracy: 0.7246 - val_loss: 0.6097\n",
            "Epoch 168/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7392 - loss: 0.5335 - val_accuracy: 0.7276 - val_loss: 0.6255\n",
            "Epoch 169/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7472 - loss: 0.5234 - val_accuracy: 0.7284 - val_loss: 0.6109\n",
            "Epoch 170/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7431 - loss: 0.5279 - val_accuracy: 0.7287 - val_loss: 0.5875\n",
            "Epoch 171/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7377 - loss: 0.5323 - val_accuracy: 0.7268 - val_loss: 0.6110\n",
            "Epoch 172/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7412 - loss: 0.5336 - val_accuracy: 0.7284 - val_loss: 0.6077\n",
            "Epoch 173/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7449 - loss: 0.5314 - val_accuracy: 0.7290 - val_loss: 0.6061\n",
            "Epoch 174/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7391 - loss: 0.5324 - val_accuracy: 0.7281 - val_loss: 0.6110\n",
            "Epoch 175/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7473 - loss: 0.5248 - val_accuracy: 0.7277 - val_loss: 0.5979\n",
            "Epoch 176/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7479 - loss: 0.5217 - val_accuracy: 0.7276 - val_loss: 0.6223\n",
            "Epoch 177/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7396 - loss: 0.5320 - val_accuracy: 0.7290 - val_loss: 0.5917\n",
            "Epoch 178/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7433 - loss: 0.5302 - val_accuracy: 0.7294 - val_loss: 0.5949\n",
            "Epoch 179/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7405 - loss: 0.5275 - val_accuracy: 0.7252 - val_loss: 0.5984\n",
            "Epoch 180/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7412 - loss: 0.5292 - val_accuracy: 0.7284 - val_loss: 0.6080\n",
            "Epoch 181/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7475 - loss: 0.5238 - val_accuracy: 0.7281 - val_loss: 0.5989\n",
            "Epoch 182/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7411 - loss: 0.5296 - val_accuracy: 0.7292 - val_loss: 0.6114\n",
            "Epoch 183/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7411 - loss: 0.5305 - val_accuracy: 0.7249 - val_loss: 0.6204\n",
            "Epoch 184/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7377 - loss: 0.5343 - val_accuracy: 0.7273 - val_loss: 0.6139\n",
            "Epoch 185/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7396 - loss: 0.5352 - val_accuracy: 0.7283 - val_loss: 0.6082\n",
            "Epoch 186/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7392 - loss: 0.5313 - val_accuracy: 0.7286 - val_loss: 0.6045\n",
            "Epoch 187/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7417 - loss: 0.5296 - val_accuracy: 0.7286 - val_loss: 0.6122\n",
            "Epoch 188/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7356 - loss: 0.5353 - val_accuracy: 0.7287 - val_loss: 0.6114\n",
            "Epoch 189/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7439 - loss: 0.5281 - val_accuracy: 0.7276 - val_loss: 0.6107\n",
            "Epoch 190/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7360 - loss: 0.5385 - val_accuracy: 0.7268 - val_loss: 0.6047\n",
            "Epoch 191/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7407 - loss: 0.5315 - val_accuracy: 0.7283 - val_loss: 0.6011\n",
            "Epoch 192/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7395 - loss: 0.5345 - val_accuracy: 0.7273 - val_loss: 0.6077\n",
            "Epoch 193/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7403 - loss: 0.5299 - val_accuracy: 0.7217 - val_loss: 0.6088\n",
            "Epoch 194/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7399 - loss: 0.5328 - val_accuracy: 0.7292 - val_loss: 0.6080\n",
            "Epoch 195/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7411 - loss: 0.5287 - val_accuracy: 0.7278 - val_loss: 0.6137\n",
            "Epoch 196/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7409 - loss: 0.5298 - val_accuracy: 0.7277 - val_loss: 0.6149\n",
            "Epoch 197/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7423 - loss: 0.5283 - val_accuracy: 0.7283 - val_loss: 0.6134\n",
            "Epoch 198/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7387 - loss: 0.5328 - val_accuracy: 0.7286 - val_loss: 0.6150\n",
            "Epoch 199/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7434 - loss: 0.5286 - val_accuracy: 0.7286 - val_loss: 0.6188\n",
            "Epoch 200/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7479 - loss: 0.5218 - val_accuracy: 0.7283 - val_loss: 0.6212\n",
            "Epoch 201/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7399 - loss: 0.5331 - val_accuracy: 0.7235 - val_loss: 0.6187\n",
            "Epoch 202/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7491 - loss: 0.5256 - val_accuracy: 0.7246 - val_loss: 0.6110\n",
            "Epoch 203/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7398 - loss: 0.5305 - val_accuracy: 0.7216 - val_loss: 0.6143\n",
            "Epoch 204/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7413 - loss: 0.5287 - val_accuracy: 0.7242 - val_loss: 0.6190\n",
            "Epoch 205/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7421 - loss: 0.5291 - val_accuracy: 0.7239 - val_loss: 0.6228\n",
            "Epoch 206/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7425 - loss: 0.5289 - val_accuracy: 0.7242 - val_loss: 0.6070\n",
            "Epoch 207/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7441 - loss: 0.5261 - val_accuracy: 0.7257 - val_loss: 0.5984\n",
            "Epoch 208/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7421 - loss: 0.5295 - val_accuracy: 0.7243 - val_loss: 0.6115\n",
            "Epoch 209/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7425 - loss: 0.5293 - val_accuracy: 0.7242 - val_loss: 0.5996\n",
            "Epoch 210/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7400 - loss: 0.5326 - val_accuracy: 0.7254 - val_loss: 0.6059\n",
            "Epoch 211/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7434 - loss: 0.5285 - val_accuracy: 0.7246 - val_loss: 0.6061\n",
            "Epoch 212/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7370 - loss: 0.5352 - val_accuracy: 0.7245 - val_loss: 0.6046\n",
            "Epoch 213/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7462 - loss: 0.5261 - val_accuracy: 0.7239 - val_loss: 0.6072\n",
            "Epoch 214/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7371 - loss: 0.5334 - val_accuracy: 0.7236 - val_loss: 0.6095\n",
            "Epoch 215/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7416 - loss: 0.5321 - val_accuracy: 0.7236 - val_loss: 0.6123\n",
            "Epoch 216/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.7394 - loss: 0.5319 - val_accuracy: 0.7243 - val_loss: 0.5963\n",
            "Epoch 217/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7460 - loss: 0.5249 - val_accuracy: 0.7246 - val_loss: 0.6160\n",
            "Epoch 218/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7408 - loss: 0.5253 - val_accuracy: 0.7242 - val_loss: 0.6153\n",
            "Epoch 219/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7453 - loss: 0.5269 - val_accuracy: 0.7238 - val_loss: 0.6022\n",
            "Epoch 220/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7462 - loss: 0.5248 - val_accuracy: 0.7243 - val_loss: 0.5902\n",
            "Epoch 221/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7358 - loss: 0.5354 - val_accuracy: 0.7238 - val_loss: 0.6021\n",
            "Epoch 222/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7413 - loss: 0.5297 - val_accuracy: 0.7246 - val_loss: 0.6071\n",
            "Epoch 223/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7409 - loss: 0.5293 - val_accuracy: 0.7235 - val_loss: 0.6124\n",
            "Epoch 224/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7434 - loss: 0.5268 - val_accuracy: 0.7242 - val_loss: 0.6088\n",
            "Epoch 225/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7394 - loss: 0.5306 - val_accuracy: 0.7246 - val_loss: 0.6131\n",
            "Epoch 226/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7438 - loss: 0.5268 - val_accuracy: 0.7242 - val_loss: 0.6178\n",
            "Epoch 227/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7460 - loss: 0.5254 - val_accuracy: 0.7239 - val_loss: 0.6006\n",
            "Epoch 228/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7446 - loss: 0.5264 - val_accuracy: 0.7236 - val_loss: 0.6219\n",
            "Epoch 229/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7382 - loss: 0.5335 - val_accuracy: 0.7235 - val_loss: 0.6344\n",
            "Epoch 230/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7382 - loss: 0.5325 - val_accuracy: 0.7239 - val_loss: 0.6074\n",
            "Epoch 231/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7430 - loss: 0.5282 - val_accuracy: 0.7245 - val_loss: 0.6224\n",
            "Epoch 232/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7380 - loss: 0.5306 - val_accuracy: 0.7243 - val_loss: 0.6139\n",
            "Epoch 233/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7426 - loss: 0.5292 - val_accuracy: 0.7207 - val_loss: 0.6438\n",
            "Epoch 234/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7399 - loss: 0.5293 - val_accuracy: 0.7232 - val_loss: 0.6200\n",
            "Epoch 235/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7396 - loss: 0.5298 - val_accuracy: 0.7281 - val_loss: 0.6363\n",
            "Epoch 236/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7452 - loss: 0.5291 - val_accuracy: 0.7230 - val_loss: 0.6301\n",
            "Epoch 237/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7440 - loss: 0.5283 - val_accuracy: 0.7233 - val_loss: 0.6226\n",
            "Epoch 238/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7428 - loss: 0.5263 - val_accuracy: 0.7233 - val_loss: 0.6325\n",
            "Epoch 239/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7470 - loss: 0.5236 - val_accuracy: 0.7235 - val_loss: 0.6276\n",
            "Epoch 240/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7409 - loss: 0.5313 - val_accuracy: 0.7232 - val_loss: 0.6328\n",
            "Epoch 241/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7411 - loss: 0.5319 - val_accuracy: 0.7224 - val_loss: 0.6519\n",
            "Epoch 242/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7450 - loss: 0.5284 - val_accuracy: 0.7245 - val_loss: 0.6371\n",
            "Epoch 243/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7424 - loss: 0.5281 - val_accuracy: 0.7239 - val_loss: 0.6302\n",
            "Epoch 244/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7426 - loss: 0.5267 - val_accuracy: 0.7235 - val_loss: 0.6319\n",
            "Epoch 245/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7424 - loss: 0.5293 - val_accuracy: 0.7232 - val_loss: 0.6332\n",
            "Epoch 246/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7433 - loss: 0.5280 - val_accuracy: 0.7233 - val_loss: 0.6307\n",
            "Epoch 247/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7408 - loss: 0.5300 - val_accuracy: 0.7236 - val_loss: 0.6363\n",
            "Epoch 248/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7407 - loss: 0.5569 - val_accuracy: 0.7233 - val_loss: 0.6054\n",
            "Epoch 249/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7411 - loss: 0.5316 - val_accuracy: 0.7230 - val_loss: 0.6044\n",
            "Epoch 250/250\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7442 - loss: 0.5277 - val_accuracy: 0.7230 - val_loss: 0.6136\n"
          ]
        }
      ],
      "source": [
        "# Compile the model\n",
        "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "\n",
        "# Train the optimized model\n",
        "history = nn.fit(\n",
        "    X_train_scaled, y_train,\n",
        "    epochs=250,  # Increased epochs to 150 on first attemt, 200 on second attempt, then to 250 on the third attempt\n",
        "    batch_size=32,\n",
        "    validation_data=(X_test_scaled, y_test),\n",
        "    verbose=1\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qBglcY8DgpdO",
        "outputId": "dea595dc-9850-4fc3-f7f3-d392a6b4ca87"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7210 - loss: 0.6110\n",
            "Test Loss: 0.6136, Test Accuracy: 0.7230\n"
          ]
        }
      ],
      "source": [
        "# Evaluate model performance\n",
        "loss, accuracy = nn.evaluate(X_test_scaled, y_test)\n",
        "print(f\"Test Loss: {loss:.4f}, Test Accuracy: {accuracy:.4f}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
